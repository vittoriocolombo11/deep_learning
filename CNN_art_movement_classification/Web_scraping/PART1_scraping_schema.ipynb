{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_scraping import Scraper\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "driver_path = \"YOUR DRIVER PATH HERE\"\n",
    "scraper = Scraper(driver_path)\n",
    "\n",
    "# 1. get to a page of the website and obtain all artists pages\n",
    "website = \"https://www.copia-di-arte.com/a/artisti/&mpos=\"\n",
    "artists_urls = [] \n",
    "pages = []\n",
    "images_links_correct = []\n",
    "# looping over all alphabetical pages\n",
    "for i in range(1000, 1026):  #1026\n",
    "    # getting all hrefs referred to artist names\n",
    "    artists_urls.extend(scraper.find_hrefs(website+str(i), scroll=False, subset_links='.html&mpos='))\n",
    "# for each artist page I get all the sub-pages (ex: raffaello page 1, raffaello page 2) \n",
    "for artist in artists_urls:\n",
    "    # getting all the pages\n",
    "    pages.extend(scraper.find_hrefs(artist, scroll=False, subset_links='.html?pgn_page='))\n",
    "# saving pages\n",
    "\n",
    "for page in pages:\n",
    "    # per ogni pagina ottengo un subset, cio√® le pagine con author name. le altre sono thrash\n",
    "    subset = page.split(\".html\")[0].split('/')[-1] + \"/\" #!!!\n",
    "     # prendo gli href dalla pagina che contengono il nome dell'artista: sono le immagini\n",
    "    images_links = scraper.find_hrefs(page, subset_links=subset)\n",
    "    # tengo solo quelle che finiscono con html: le altre sono thrash\n",
    "    images_links_correct.extend([image for image in images_links if image[-4:]=='html']) \n",
    "\n",
    "# first checkpoint\n",
    "with open(\"images_links_correct.txt\",\"w\") as f:\n",
    "    for line in images_links_correct: \n",
    "        f.write(line + '\\n')\n",
    "        \n",
    "        \n",
    "f = open(\"images_links_correct.txt\", 'r')\n",
    "file = f.read()\n",
    "images_links_correct = file.splitlines()\n",
    "images_links_correct = list(set(images_links_correct))\n",
    "print(len(images_links_correct))\n",
    "\n",
    "\n",
    "links = [] \n",
    "artists = []    \n",
    "art_movement = []\n",
    "title = []\n",
    "for i in range(len(images_links_correct)):  \n",
    "    img_link = images_links_correct[i]\n",
    "    scraper.get_url(img_link)\n",
    "    try:\n",
    "        elements = scraper.find_classes(url=img_link, tag=\"div\", class_name=\"val\")\n",
    "        #element 0 is artist name\n",
    "        if len(elements) != 0:\n",
    "            links.append(img_link)\n",
    "            artists.append(elements[0].replace(\"\\n\",\"\").replace(\"\\t\",\"\"))\n",
    "            #element 1 is artistic movement\n",
    "            art_movement.append(elements[1].replace(\"\\n\",\"\").replace(\"\\t\",\"\"))\n",
    "            #element 2 is title\n",
    "            title.append(elements[2].replace(\"\\n\",\"\").replace(\"\\t\",\"\"))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "result = pd.DataFrame({\"image_link\":links, \"artists\":artists, \"art_movement\": art_movement, \"title\":title})\n",
    "result.to_csv(\"links_final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
